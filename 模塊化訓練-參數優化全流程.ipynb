{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "374e94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split,Dataset\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.optim as optim\n",
    "\n",
    "import pywt\n",
    "from scipy.signal import welch\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# 設置設備\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e233e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGUtil:\n",
    "    @staticmethod\n",
    "    def load_data(file_path, column_name='spike hz'):\n",
    "        \"\"\"Load EEG data from a CSV file.\"\"\"\n",
    "        data = pd.read_csv(file_path)\n",
    "        signal = data[column_name].values\n",
    "        return signal\n",
    "\n",
    "    @staticmethod\n",
    "    def padding(signal, target_length):\n",
    "        \"\"\"Pad or truncate signal to the target length.\"\"\"\n",
    "        if len(signal) < target_length:\n",
    "            return np.pad(signal, (0, target_length - len(signal)), 'constant', constant_values=-1)\n",
    "        return signal[:target_length]\n",
    "\n",
    "    @staticmethod\n",
    "    def wavelet_transform(signal):\n",
    "        \"\"\"Perform Wavelet Transform and extract features.\"\"\"\n",
    "        coeffs = pywt.wavedec(signal, 'db4', level=5)\n",
    "        features = []\n",
    "        for i in range(1, len(coeffs)):\n",
    "            features.extend([np.mean(coeffs[i]), np.std(coeffs[i])])\n",
    "        return np.array(features)\n",
    "\n",
    "    @staticmethod\n",
    "    def psd_transform(signal, fs=0.2, nperseg=128):\n",
    "        \"\"\"Perform Power Spectral Density analysis and extract features.\"\"\"\n",
    "        freqs, psd = welch(signal, fs=fs, nperseg=nperseg)\n",
    "        return psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40cdc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_folder, outcome_file=None, target_length=600, strategy='padding', use_labels=False):\n",
    "        self.use_labels=use_labels\n",
    "        self.data_folder = data_folder\n",
    "        self.target_length = target_length\n",
    "        self.strategy = strategy\n",
    "        self.file_list = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "        \n",
    "        # Load outcomes if provided\n",
    "        self.outcome_dict = {}\n",
    "        if use_labels and outcome_file is not None:\n",
    "            self.outcome_data = pd.read_csv(outcome_file)\n",
    "            self.outcome_dict = self.outcome_data.set_index('pat_ID')['outcome'].to_dict()\n",
    "            # 仅保留有标签的文件\n",
    "            self.file_list = [f for f in self.file_list if f.split('.')[0] in self.outcome_dict]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.file_list[idx]\n",
    "        patient_id = filename.split('.')[0]\n",
    "        file_path = os.path.join(self.data_folder, filename)\n",
    "        signal = EEGUtil.load_data(file_path, column_name='BCI')\n",
    "\n",
    "        # Process the signal\n",
    "        processed_signal = self.process_signal(signal)\n",
    "\n",
    "        # Get the label if available\n",
    "        label=-1\n",
    "        if self.use_labels :\n",
    "            label = self.get_label(patient_id)\n",
    "            \n",
    "        return torch.tensor(processed_signal, dtype=torch.float32).unsqueeze(0), label  # 增加通道维度\n",
    "\n",
    "    def process_signal(self, signal):\n",
    "        if self.strategy == 'padding':\n",
    "            return EEGUtil.padding(signal, self.target_length)\n",
    "        elif self.strategy == 'wavelet':\n",
    "            return EEGUtil.wavelet_transform(signal)\n",
    "        elif self.strategy == 'psd':\n",
    "            return EEGUtil.psd_transform(signal)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid processing strategy\")\n",
    "\n",
    "    def get_label(self, patient_id):\n",
    "        if patient_id in self.outcome_dict:\n",
    "            outcome = self.outcome_dict[patient_id]\n",
    "            return 1 if outcome == 'Good Outcome' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809a29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_channels = 128\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv1d(1, initial_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU()\n",
    "        ]\n",
    "\n",
    "        in_channels = initial_channels\n",
    "        for i in range(3):  # 3 more layers to make 4 in total\n",
    "            out_channels = in_channels // 2\n",
    "            layers.extend([\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU()\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        self.fc_mean = nn.Linear(in_channels * seq_length, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(in_channels * seq_length, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mean = self.fc_mean(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mean, logvar\n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length):\n",
    "        super(CNNDecoder, self).__init__()\n",
    "        self.seq_length=seq_length\n",
    "        self.latent_dim = latent_dim\n",
    "        self.fc = nn.Linear(latent_dim, initial_channels // 8 * seq_length)  # Match the output channel of the encoder\n",
    "\n",
    "        layers = [nn.LeakyReLU()]\n",
    "        in_channels = initial_channels // 8\n",
    "        for i in range(3):\n",
    "            out_channels = in_channels * 2\n",
    "            layers.extend([\n",
    "                nn.ConvTranspose1d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU()\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Remove the last LeakyReLU and add a final ConvTranspose to match the Encoder's starting channel\n",
    "        layers.pop()\n",
    "        layers.append(nn.ConvTranspose1d(in_channels, 1, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(x.size(0), initial_channels // 8, self.seq_length)\n",
    "        x = self.decoder(x)\n",
    "        return F.leaky_relu(x)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim, seq_length):  # 接受 seq_length 作为参数\n",
    "        super(VAE, self).__init__()\n",
    "        self.seq_length=seq_length\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = CNNEncoder(latent_dim, seq_length)  # 将 seq_length 传递给 CNNEncoder\n",
    "        self.decoder = CNNDecoder(latent_dim, seq_length)  # 将 seq_length 传递给 CNNDecoder\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction, mean, logvar\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            mean, logvar = self.encoder(x)\n",
    "            z = self.reparameterize(mean, logvar)\n",
    "        return z\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7989eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, alpha, kl_loss_enabled=True):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data, label in dataloader:  # We don't use the labels during unsupervised training for VAE\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        reconstruction, mean, logvar = model(data)\n",
    "\n",
    "        # Compute the reconstruction loss (mean squared error)\n",
    "        recon_loss = criterion(reconstruction, data)\n",
    "\n",
    "        # Compute the KL divergence loss\n",
    "        kl_loss = -0.5 * torch.mean(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "        # Combine the losses\n",
    "        loss = recon_loss + (alpha * kl_loss if kl_loss_enabled else 0)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)  # Accumulate the total loss for this batch\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)  # Calculate the average loss per sample\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:  # 注意：解包数据，将信号和标签分别取出\n",
    "            data = data.to(device)\n",
    "            reconstruction, _, _ = model(data)\n",
    "            loss = criterion(reconstruction, data)\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def get_latent_variables(model, dataloader):\n",
    "    model.eval()\n",
    "    all_latent_vars = []\n",
    "    with torch.no_grad():\n",
    "        for data, label  in dataloader:\n",
    "            data = data.to(device)\n",
    "            _, mean, _ = model(data)\n",
    "            all_latent_vars.append(mean.detach().cpu())\n",
    "    return torch.cat(all_latent_vars)\n",
    "\n",
    "\n",
    "def extract_latent_features(vae_model, dataset):\n",
    "    latent_features = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        signal, label = dataset[i]  # 从数据集中获取信号和标签\n",
    "\n",
    "        # 将信号放入设备\n",
    "        signal = signal.unsqueeze(0).to(device)  # 增加 batch 维度\n",
    "\n",
    "        # 获取潜在表示\n",
    "        with torch.no_grad():\n",
    "            latent_vector = vae_model.get_embedding(signal).cpu().numpy()\n",
    "        latent_features.append(latent_vector.flatten())\n",
    "        \n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(latent_features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1179e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(data_folder, valid_outcome_data, latent_dim=10, initial_channels=128, seq_length=1139,\n",
    "                       batch_size=32, epochs=100, alpha=1e-6, patience=3, strategy='padding'):\n",
    "    # 1. 创建 EEG 数据集和数据加载器\n",
    "    eeg_dataset = EEGDataset(data_folder, valid_outcome_data, target_length=seq_length, strategy=strategy, use_labels=False)\n",
    "    train_size = int(0.8 * len(eeg_dataset))\n",
    "    test_size = len(eeg_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(eeg_dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 2. 定义 VAE 模型、损失函数和优化器\n",
    "    vae_model = VAE(latent_dim, seq_length).to(device)  # 传递 seq_length\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(vae_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    # 3. 训练和测试损失列表，用于绘制曲线\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # 4. 早停相关变量\n",
    "    best_test_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # 5. 训练循环\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        train_loss = train(vae_model, train_loader, optimizer, criterion, alpha)\n",
    "        test_loss = test(vae_model, test_loader, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        #print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        # 检查早停条件\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            #print(\"Validation loss has not improved for {} epochs. Early stopping...\".format(patience))\n",
    "            break\n",
    "\n",
    "    # 6. 提取潜在特征\n",
    "    eeg_dataset_with_outcomes = EEGDataset(data_folder, valid_outcome_data, target_length=seq_length, strategy=strategy, use_labels=True)\n",
    "    latent_features, labels = extract_latent_features(vae_model, eeg_dataset_with_outcomes)\n",
    "\n",
    "    # 7. 使用分层划分进行训练和测试集划分\n",
    "    X_train, X_test, y_train, y_test = train_test_split(latent_features, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "    # 8. 创建并训练 SVM 模型\n",
    "    #svm_model = SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=42)\n",
    "    #svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # 9. 预测并评估模型\n",
    "    #y_pred = svm_model.predict(X_test)\n",
    "    #accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    #print(f\"Accuracy of SVM on latent features: {accuracy:.4f}\")\n",
    "    #print(\"\\nClassification Report:\")\n",
    "    #report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    #print(report)\n",
    "    #print(\"\\nConfusion Matrix:\")\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    #print(cm)\n",
    "    #print(\"\\n\")\n",
    "    #======================================================================================\n",
    "    # 8. 创建并训练 XGBoost 模型\n",
    "    xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')  # 设定不使用标签编码\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # 9. 预测并评估模型\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy of XGBoost on latent features: {accuracy:.4f}\")\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "\n",
    "    # 10. 返回结果\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'svm_accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm.tolist()  # 保存为列表格式\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99176ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def optimize_latent_dimensions(data_folder, valid_outcome_data, min_latent_dim=1, max_latent_dim=100, \n",
    "                               initial_channels=128, seq_length=1139, batch_size=32, \n",
    "                               epochs=100, alpha=1e-6, patience=10, strategy='padding'):\n",
    "    # 检查结果文件是否存在\n",
    "    results_file = 'latent_optimization_results.csv'\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        # 读取已存在的结果文件\n",
    "        existing_results = pd.read_csv(results_file)\n",
    "        last_latent_dim = existing_results['Latent Dimension'].max()  # 找到最后一次的潜在维度\n",
    "    else:\n",
    "        # 如果文件不存在，则从最小潜在维度开始\n",
    "        last_latent_dim = min_latent_dim - 1\n",
    "\n",
    "    # 遍历潜在维度\n",
    "    for latent_dim in range(last_latent_dim + 1, max_latent_dim + 1):\n",
    "        print(f\"Training VAE with latent dimension: {latent_dim}\")\n",
    "        results = train_and_evaluate(data_folder=data_folder, valid_outcome_data=valid_outcome_data,\n",
    "                                      latent_dim=latent_dim, initial_channels=initial_channels,\n",
    "                                      seq_length=seq_length, batch_size=batch_size,\n",
    "                                      epochs=epochs, alpha=alpha, patience=patience, strategy=strategy)\n",
    "\n",
    "        # 将结果存储到表格中\n",
    "        new_result_df = pd.DataFrame({\n",
    "            'Latent Dimension': [latent_dim],\n",
    "            'Train Loss': [results['train_losses']],  \n",
    "            'Test Loss': [results['test_losses']],    \n",
    "            'XGBoost Accuracy': [results['svm_accuracy']],\n",
    "            'Classification Report': [results['classification_report']],\n",
    "            'Confusion Matrix': [results['confusion_matrix']]\n",
    "        })\n",
    "\n",
    "        # 追加结果到CSV文件\n",
    "        if os.path.exists(results_file):\n",
    "            new_result_df.to_csv(results_file, mode='a', header=False, index=False)  # 追加到已有文件\n",
    "        else:\n",
    "            new_result_df.to_csv(results_file, index=False)  # 创建新文件并写入\n",
    "\n",
    "        print(f\"Results for latent dimension {latent_dim} saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deab2d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VAE with latent dimension: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████████████████| 100/100 [13:01<00:00,  7.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7111\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62 12]\n",
      " [14  2]]\n",
      "Results for latent dimension 1 saved.\n",
      "Training VAE with latent dimension: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  75%|█████████████████▎     | 75/100 [09:58<03:19,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.6667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[58 16]\n",
      " [14  2]]\n",
      "Results for latent dimension 2 saved.\n",
      "Training VAE with latent dimension: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████████████████| 100/100 [12:55<00:00,  7.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 11]\n",
      " [12  4]]\n",
      "Results for latent dimension 3 saved.\n",
      "Training VAE with latent dimension: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████████████████| 100/100 [12:56<00:00,  7.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  8]\n",
      " [12  4]]\n",
      "Results for latent dimension 4 saved.\n",
      "Training VAE with latent dimension: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  77%|█████████████████▋     | 77/100 [10:16<03:04,  8.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7556\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 11]\n",
      " [11  5]]\n",
      "Results for latent dimension 5 saved.\n",
      "Training VAE with latent dimension: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████████████████| 100/100 [13:27<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7222\n",
      "\n",
      "Confusion Matrix:\n",
      "[[61 13]\n",
      " [12  4]]\n",
      "Results for latent dimension 6 saved.\n",
      "Training VAE with latent dimension: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  81%|█████████████████    | 81/100 [1:40:19<23:32, 74.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[67  7]\n",
      " [11  5]]\n",
      "Results for latent dimension 7 saved.\n",
      "Training VAE with latent dimension: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  98%|██████████████████████▌| 98/100 [12:40<00:15,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  9]\n",
      " [11  5]]\n",
      "Results for latent dimension 8 saved.\n",
      "Training VAE with latent dimension: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████████████████| 100/100 [12:53<00:00,  7.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62 12]\n",
      " [11  5]]\n",
      "Results for latent dimension 9 saved.\n",
      "Training VAE with latent dimension: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  61%|██████████████         | 61/100 [08:00<05:07,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7889\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  8]\n",
      " [11  5]]\n",
      "Results for latent dimension 10 saved.\n",
      "Training VAE with latent dimension: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  91%|████████████████████▉  | 91/100 [11:53<01:10,  7.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64 10]\n",
      " [13  3]]\n",
      "Results for latent dimension 11 saved.\n",
      "Training VAE with latent dimension: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  61%|██████████████         | 61/100 [08:01<05:07,  7.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7222\n",
      "\n",
      "Confusion Matrix:\n",
      "[[60 14]\n",
      " [11  5]]\n",
      "Results for latent dimension 12 saved.\n",
      "Training VAE with latent dimension: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  83%|███████████████████    | 83/100 [10:53<02:13,  7.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64 10]\n",
      " [14  2]]\n",
      "Results for latent dimension 13 saved.\n",
      "Training VAE with latent dimension: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  62%|██████████████▎        | 62/100 [08:10<05:00,  7.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  8]\n",
      " [12  4]]\n",
      "Results for latent dimension 14 saved.\n",
      "Training VAE with latent dimension: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  55%|████████████▋          | 55/100 [07:16<05:57,  7.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[65  9]\n",
      " [11  5]]\n",
      "Results for latent dimension 15 saved.\n",
      "Training VAE with latent dimension: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  71%|████████████████▎      | 71/100 [09:21<03:49,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 11]\n",
      " [ 9  7]]\n",
      "Results for latent dimension 16 saved.\n",
      "Training VAE with latent dimension: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  55%|████████████▋          | 55/100 [07:17<05:57,  7.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 11]\n",
      " [10  6]]\n",
      "Results for latent dimension 17 saved.\n",
      "Training VAE with latent dimension: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  69%|███████████████▊       | 69/100 [09:07<04:05,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[67  7]\n",
      " [13  3]]\n",
      "Results for latent dimension 18 saved.\n",
      "Training VAE with latent dimension: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  86%|███████████████████▊   | 86/100 [11:20<01:50,  7.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 11]\n",
      " [13  3]]\n",
      "Results for latent dimension 19 saved.\n",
      "Training VAE with latent dimension: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  94%|█████████████████████▌ | 94/100 [12:22<00:47,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on latent features: 0.7778\n",
      "\n",
      "Confusion Matrix:\n",
      "[[66  8]\n",
      " [12  4]]\n",
      "Results for latent dimension 20 saved.\n"
     ]
    }
   ],
   "source": [
    "# 调用该函数进行潜在维度优化\n",
    "optimize_latent_dimensions(data_folder='5min_smoothed_data/', valid_outcome_data='valid_patients_outcome.csv',min_latent_dim=1, max_latent_dim=20,initial_channels=128, seq_length=1139, batch_size=32, \n",
    "                               epochs=100, alpha=1e-6, patience=10, strategy='padding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad373ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Accuracy Results with LD 7:\n",
      "Final Train Loss: 0.010933\n",
      "Final Test Loss: 0.015386\n",
      "\n",
      "Best XGBoost Accuracy: 0.8000\n",
      "\n",
      "Classification Report:\n",
      "Label 0: Precision = 0.8590, Recall = 0.9054, F1 Score = 0.8816\n",
      "Label 1: Precision = 0.4167, Recall = 0.3125, F1 Score = 0.3571\n",
      "Label macro avg: Precision = 0.6378, Recall = 0.6090, F1 Score = 0.6194\n",
      "Label weighted avg: Precision = 0.7803, Recall = 0.8000, F1 Score = 0.7883\n",
      "\n",
      "Confusion Matrix:\n",
      "True Negatives: 67, False Positives: 7\n",
      "False Negatives: 11, True Positives: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "# 读取优化结果的 CSV 文件\n",
    "results_file = 'latent_optimization_results.csv'\n",
    "results_df = pd.read_csv(results_file)\n",
    "\n",
    "# 找到 SVM 准确度最高的行\n",
    "best_row = results_df.loc[results_df['XGBoost Accuracy'].idxmax()]\n",
    "# 打印出对应的数据\n",
    "print(f'Best XGBoost Accuracy Results with LD {best_row[\"Latent Dimension\"]}:')\n",
    "\n",
    "# 提取训练和测试损失\n",
    "train_losses = eval(best_row['Train Loss'])  # 将字符串转换为列表\n",
    "test_losses = eval(best_row['Test Loss'])    # 将字符串转换为列表\n",
    "\n",
    "# 打印最后的训练损失和测试损失\n",
    "print(f\"Final Train Loss: {train_losses[-1]:.6f}\")  # 打印最后一个训练损失\n",
    "print(f\"Final Test Loss: {test_losses[-1]:.6f}\")    # 打印最后一个测试损失\n",
    "\n",
    "# 打印分类报告\n",
    "print(f'\\nBest XGBoost Accuracy: {best_row[\"XGBoost Accuracy\"]:.4f}')\n",
    "\n",
    "classification_reports = ast.literal_eval(best_row['Classification Report'])  # 将字符串转换为字典\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "for label, metrics in classification_reports.items():\n",
    "    # 确保 'metrics' 是字典\n",
    "    if isinstance(metrics, dict):  \n",
    "        precision = metrics['precision']\n",
    "        recall = metrics['recall']\n",
    "        f1_score = metrics['f1-score']\n",
    "        print(f\"Label {label}: Precision = {precision:.4f}, Recall = {recall:.4f}, F1 Score = {f1_score:.4f}\")\n",
    "\n",
    "# 打印混淆矩阵\n",
    "confusion_matrixs = ast.literal_eval(best_row['Confusion Matrix'])  # 使用 literal_eval 来解析\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives: {confusion_matrixs[0][0]}, False Positives: {confusion_matrixs[0][1]}\")\n",
    "print(f\"False Negatives: {confusion_matrixs[1][0]}, True Positives: {confusion_matrixs[1][1]}\")\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training and Testing Loss for Best XGBoost Accuracy: {best_row[\"XGBoost Accuracy\"]:.4f}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f2827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
