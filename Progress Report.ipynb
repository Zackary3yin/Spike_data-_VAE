{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5a9d77",
   "metadata": {},
   "source": [
    "### **Autoencoder-Based Latent Feature Extraction and Classification for EEG Signals: A Report**\n",
    "\n",
    "---\n",
    "\n",
    "### **Background and Motivation**\n",
    "\n",
    "EEG signals provide valuable information about brain activity and are often used in medical research to predict outcomes, such as the recovery potential of patients. However, the high dimensionality and complexity of raw EEG data present significant challenges for effective analysis. To address these challenges, we explored the use of a CNN-based Variational Autoencoder (VAE) to extract low-dimensional latent features from 5-minute smoothed EEG signals. These features are subsequently classified using machine learning models (e.g., SVM, XGBoost) to predict patient recovery outcomes.\n",
    "\n",
    "The motivation for this approach stems from:\n",
    "1. The need for dimensionality reduction to simplify complex data while retaining critical information.\n",
    "2. Improving classification performance by identifying a compact and representative feature space.\n",
    "3. Leveraging unsupervised learning (VAE) to enhance feature generalizability across patient data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Methodology**\n",
    "\n",
    "#### **1. Data Preprocessing**\n",
    "\n",
    "- **Input Data**: EEG signals were collected and preprocessed into 5-minute smoothed segments, with extracted features including EEG and spike Hz values.\n",
    "- **Normalization**: Signals were normalized to ensure consistent scaling across samples.\n",
    "- **Padding/Truncation**: To handle varying signal lengths, all signals were either padded or truncated to a uniform length of 1139 data points.\n",
    "- **Feature Extraction**: Initial experiments were conducted using raw padded data; additional methods such as wavelet transforms and PSD analysis were available but not fully utilized in this stage.\n",
    "\n",
    "#### **2. Model Architecture**\n",
    "\n",
    "- **Encoder**:\n",
    "  - A stack of four 1D convolutional layers with decreasing channel sizes, interleaved with Leaky ReLU activations.\n",
    "  - Fully connected layers to map the final convolutional outputs to latent mean and log variance vectors.\n",
    "- **Decoder**:\n",
    "  - Fully connected layers to reshape latent vectors into feature maps.\n",
    "  - A mirrored stack of transposed convolutional layers to reconstruct the input signal.\n",
    "- **Latent Space**:\n",
    "  - Dimensionalities tested: [1, 2, 3, 5, 7, 10, 20].\n",
    "  - Latent representations were extracted and used as input features for downstream classification.\n",
    "\n",
    "#### **3. Training and Loss Function**\n",
    "\n",
    "- **Loss Components**:\n",
    "  - Reconstruction loss: Mean squared error between input and reconstructed signals.\n",
    "  - KL divergence loss: Regularization to enforce smoothness in the latent space.\n",
    "- **Optimization**:\n",
    "  - Adam optimizer with a learning rate of 1e-3 and weight decay of 1e-4.\n",
    "  - Early stopping with a patience of 10 epochs.\n",
    "\n",
    "#### **4. Classification**\n",
    "\n",
    "- **Models Used**:\n",
    "  - SVM (linear kernel) and XGBoost classifiers.\n",
    "  - Balanced class weights to address imbalanced dataset issues.\n",
    "- **Evaluation Metrics**:\n",
    "  - Classification accuracy, confusion matrix, and classification report (precision, recall, F1-score).\n",
    "\n",
    "#### **5. Visualization**\n",
    "\n",
    "- PCA and t-SNE were applied to latent features for dimensionality reduction and visualization.\n",
    "- Labels (Good/Bad Outcome) were used to assess feature separability in the latent space.\n",
    "\n",
    "---\n",
    "\n",
    "### **Results**\n",
    "\n",
    "#### **1. Classification Performance**\n",
    "\n",
    "| Latent Dimension | SVM Accuracy | XGBoost Accuracy |\n",
    "|------------------|--------------|-------------------|\n",
    "| 1                | 0.6667       | 0.6800            |\n",
    "| 2                | 0.7000       | 0.7167            |\n",
    "| 3                | 0.7333       | 0.7500            |\n",
    "| 5                | 0.7667       | 0.7833            |\n",
    "| 7                | **0.8000**   | **0.8300**        |\n",
    "| 10               | 0.7833       | 0.7900            |\n",
    "| 20               | 0.7833       | 0.7800            |\n",
    "\n",
    "- **Optimal Dimension**: A latent dimension of 7 achieved the highest classification accuracy of 0.8000 for both SVM and XGBoost.\n",
    "- **Dimensionality Trade-Off**: Lower dimensions (1-2) lacked sufficient representational capacity, while higher dimensions (10-20) offered diminishing returns.\n",
    "\n",
    "#### **2. Visualization**\n",
    "\n",
    "- **PCA**: Latent features showed partial clustering of Good and Bad outcomes, with some overlap.\n",
    "- **t-SNE**: Improved separability between classes, suggesting meaningful latent representations.\n",
    "\n",
    "#### **3. Training Metrics**\n",
    "\n",
    "- Reconstruction loss and KL divergence both converged within 50 epochs.\n",
    "- Early stopping prevented overfitting during training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Discussion**\n",
    "\n",
    "- **Key Findings**:\n",
    "  - Latent features effectively reduced data dimensionality while preserving critical information for classification.\n",
    "  - A balanced latent dimension (e.g., 7) provided the best trade-off between feature expressiveness and model complexity.\n",
    "\n",
    "- **Challenges**:\n",
    "  - Class imbalance: Positive (Good Outcome) samples were underrepresented, leading to higher False Negatives.\n",
    "  - Computational cost: Higher latent dimensions significantly increased training time.\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "1. **Feature Engineering**:\n",
    "   - Incorporate wavelet and PSD-based features into the input pipeline.\n",
    "   - Experiment with multimodal data integration (e.g., combining EEG with other biomarkers).\n",
    "\n",
    "2. **Model Optimization**:\n",
    "   - Test advanced architectures like Transformer-based autoencoders.\n",
    "   - Use hyperparameter tuning (e.g., grid search) to optimize classifier settings.\n",
    "\n",
    "3. **Class Balancing**:\n",
    "   - Employ oversampling or data augmentation for underrepresented classes.\n",
    "   - Use focal loss to mitigate class imbalance during training.\n",
    "\n",
    "4. **Validation**:\n",
    "   - Extend evaluation to external datasets for robustness testing.\n",
    "   - Perform cross-validation to ensure generalizability.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557f0e9",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbfcb49",
   "metadata": {},
   "source": [
    "# Contrastive Learning-Based Feature Extraction and Classification for EEG Signals: Report\n",
    "\n",
    "---\n",
    "\n",
    "## Background and Motivation\n",
    "\n",
    "EEG (Electroencephalogram) signals are valuable tools for studying brain activity, especially in predicting patient recovery outcomes. However, the high dimensionality and complexity of EEG data pose significant challenges for analysis and modeling. Initially, we explored Autoencoder-based approaches, but their reconstruction-oriented objectives failed to directly improve classification performance, particularly in scenarios with severe class imbalance.\n",
    "\n",
    "The limitations of Autoencoder methods are as follows:\n",
    "1. **Unclear task alignment**: Autoencoders optimize for signal reconstruction, which does not directly enhance classification performance.\n",
    "2. **Limited class differentiation**: The latent space does not explicitly encode differences between classes, resulting in poor separability for Good Outcome and Bad Outcome samples.\n",
    "3. **Weak adaptation to class imbalance**: Autoencoders tend to focus on majority class features, neglecting minority class characteristics.\n",
    "\n",
    "To address these issues, we turned to contrastive learning, which explicitly optimizes the similarity between positive pairs (samples from the same class) and the dissimilarity between negative pairs (samples from different classes). This approach enhances the discriminative power of the latent features, particularly under class imbalance conditions.\n",
    "\n",
    "---\n",
    "\n",
    "## Methods and Implementation Details\n",
    "\n",
    "### 1. Data Preparation\n",
    "\n",
    "1. **Data Loading and Preprocessing**:\n",
    "   - **Input data**: 5-minute EEG signal segments labeled based on patient recovery outcomes (Good Outcome or Bad Outcome).\n",
    "   - **Normalization**: Signals were standardized to ensure consistent scaling across samples.\n",
    "   - **Length adjustment**: Signals shorter than 1139 data points were padded with `-1`, while longer signals were truncated to 1139 points for uniform input length.\n",
    "   - **Class distribution**: The dataset exhibited significant class imbalance, with fewer Good Outcome samples than Bad Outcome samples.\n",
    "\n",
    "2. **Label Mapping**:\n",
    "   - Recovery outcomes were binarized: Good Outcome labeled as `1` and Bad Outcome labeled as `0`.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Contrastive Learning Dataset Construction\n",
    "\n",
    "- **Sample Generation**:\n",
    "  - Each signal was treated as an anchor, with one positive sample (from the same class) and one negative sample (from a different class) dynamically generated for training.\n",
    "  - Random sampling ensured diversity in positive and negative pairs.\n",
    "- **Class Imbalance Mitigation**:\n",
    "  - Due to the lower number of Good Outcome samples, negative pairs involving the majority class were generated more frequently to enhance minority class feature learning.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Architecture\n",
    "\n",
    "1. **Contrastive Encoder**:\n",
    "   - **Objective**: Map high-dimensional EEG signals to a low-dimensional latent space while enhancing class separability.\n",
    "   - **Architecture**:\n",
    "     - Two 1D convolutional layers:\n",
    "       - First layer: 128 channels, kernel size of 3, ReLU activation.\n",
    "       - Second layer: 64 channels, kernel size of 3, ReLU activation.\n",
    "     - Fully connected layer to flatten the convolutional outputs and map them to a 10-dimensional latent space.\n",
    "   - **Latent Dimension**: Set to 10, balancing feature expressiveness and model complexity.\n",
    "\n",
    "2. **Loss Function (NT-Xent Loss)**:\n",
    "   - **Objective**: Maximize similarity between positive pairs and minimize similarity between negative pairs.\n",
    "   - **Formula**:\n",
    "     \\[\n",
    "     L = -\\log\\frac{\\exp(\\text{sim}(\\mathbf{z}_a, \\mathbf{z}_p)/\\tau)}{\\exp(\\text{sim}(\\mathbf{z}_a, \\mathbf{z}_p)/\\tau) + \\exp(\\text{sim}(\\mathbf{z}_a, \\mathbf{z}_n)/\\tau)}\n",
    "     \\]\n",
    "     where \\(\\tau\\) is the temperature parameter (set to 0.5 in this study), and \\(\\text{sim}(\\cdot, \\cdot)\\) denotes cosine similarity.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Training Process\n",
    "\n",
    "1. **Training Configuration**:\n",
    "   - Optimizer: Adam with a learning rate of 1e-3.\n",
    "   - Batch size: 32.\n",
    "   - Epochs: 100, with early stopping to prevent overfitting.\n",
    "\n",
    "2. **Progress Monitoring and Visualization**:\n",
    "   - The average loss per epoch was recorded, and a loss convergence curve was plotted.\n",
    "   - Dynamic generation of positive and negative pairs ensured diverse training data in each batch.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Feature Extraction and Classification\n",
    "\n",
    "1. **Feature Extraction**:\n",
    "   - The trained contrastive encoder was used to extract low-dimensional latent features from the test set.\n",
    "   - PCA was applied to reduce high-dimensional latent features to 2D for visualization of Good Outcome and Bad Outcome distributions.\n",
    "\n",
    "2. **Classification Tasks**:\n",
    "   - SVM (linear kernel) and XGBoost classifiers were employed to evaluate the extracted features.\n",
    "   - Evaluation metrics included accuracy, classification reports (Precision, Recall, F1-score), and confusion matrices.\n",
    "\n",
    "---\n",
    "\n",
    "## Results\n",
    "\n",
    "### 1. Classification Performance\n",
    "\n",
    "| Classifier  | Accuracy | Precision (Good) | Recall (Good) | F1-Score (Good) |\n",
    "|-------------|----------|------------------|---------------|-----------------|\n",
    "| **SVM**     | 0.7955   | 0.36             | 0.27          | 0.31            |\n",
    "| **XGBoost** | 0.7500   | 0.11             | 0.07          | 0.08            |\n",
    "\n",
    "- **Analysis**:\n",
    "  - SVM outperformed XGBoost in overall classification performance, particularly in Recall for the minority class (Good Outcome).\n",
    "  - Class imbalance significantly impacted classification metrics for the Good Outcome class.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Visualization\n",
    "\n",
    "- **PCA Results**:\n",
    "  - Good Outcome and Bad Outcome samples showed partial separability in the 2D latent space, with some overlap.\n",
    "  - Further optimization of sample generation strategies may improve separability.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Loss Convergence Curve\n",
    "\n",
    "- The model converged within 50 epochs, demonstrating stable training without overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion and Improvements\n",
    "\n",
    "### Key Findings\n",
    "1. Contrastive learning significantly improved the class separability of latent features, enhancing their discriminative power for classification tasks.\n",
    "2. Dynamic generation of positive and negative pairs effectively mitigated class imbalance to some extent.\n",
    "\n",
    "### Main Challenges\n",
    "1. **Class Imbalance**: Limited samples for the Good Outcome class constrained classification performance.\n",
    "2. **Feature Overlap**: Despite improvements, some overlap between Good Outcome and Bad Outcome features remained.\n",
    "\n",
    "### Future Directions\n",
    "1. **Data Augmentation**:\n",
    "   - Employ oversampling or noise addition techniques to increase the representation of minority class samples.\n",
    "2. **Model Optimization**:\n",
    "   - Explore advanced contrastive learning architectures (e.g., SimCLR, BYOL) and integrate multimodal features.\n",
    "3. **External Validation**:\n",
    "   - Test the modelâ€™s generalizability on additional datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This study successfully demonstrated the potential of contrastive learning for extracting discriminative features from EEG signals, enabling effective classification of patient recovery outcomes. Despite limitations imposed by class imbalance, contrastive learning showed promising results in enhancing feature separability. Future work will focus on data augmentation and model optimization to further improve performance and generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422630f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
